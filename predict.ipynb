{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 디렉토리 구조\n",
    "- dataset : 이미지 파일 저장 폴더\n",
    "- pretrain : pre-trained 모델 파일저장 \n",
    "- loaders : 모델 로드 관련 소스코드\n",
    "- models : 모델 구조 관련 소스코드 \n",
    "- result : dewarping 된 이미지 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "from models import get_model\n",
    "from loaders import get_loader\n",
    "from utils import convert_state_dict\n",
    "\n",
    "# model save path\n",
    "wc_model_path = './pretrain/unetnc_doc3d.pkl' # shape network\n",
    "bm_model_path = './pretrain/dnetccnl_doc3d.pkl' # texture mapping network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwarp(img, bm):\n",
    "    w,h=img.shape[0],img.shape[1]\n",
    "    bm = bm.transpose(1, 2).transpose(2, 3).detach().cpu().numpy()[0,:,:,:]\n",
    "    bm0=cv2.blur(bm[:,:,0],(3,3))\n",
    "    bm1=cv2.blur(bm[:,:,1],(3,3))\n",
    "    bm0=cv2.resize(bm0,(h,w))\n",
    "    bm1=cv2.resize(bm1,(h,w))\n",
    "    bm=np.stack([bm0,bm1],axis=-1)\n",
    "    bm=np.expand_dims(bm,0)\n",
    "    bm=torch.from_numpy(bm).double()\n",
    "\n",
    "    img = img.astype(float) / 255.0\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img).double()\n",
    "\n",
    "    res = F.grid_sample(input=img, grid=bm)\n",
    "    res = res[0].numpy().transpose((1, 2, 0))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img_path, wc_model_path, bm_model_path):\n",
    "    wc_model_file_name = os.path.split(wc_model_path)[1]\n",
    "    wc_model_name = wc_model_file_name[:wc_model_file_name.find('_')]\n",
    "\n",
    "    bm_model_file_name = os.path.split(bm_model_path)[1]\n",
    "    bm_model_name = bm_model_file_name[:bm_model_file_name.find('_')]\n",
    "    \n",
    "    wc_n_classes = 3\n",
    "    bm_n_classes = 2\n",
    "\n",
    "    wc_img_size=(256,256)\n",
    "    bm_img_size=(128,128)\n",
    "    \n",
    "    # Image Read\n",
    "    print(\"Read Input Image from : {}\".format(img_path))\n",
    "    imgorg = cv2.imread(img_path)\n",
    "    imgorg = cv2.cvtColor(imgorg, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(imgorg, wc_img_size)\n",
    "    img = img[:, :, ::-1]\n",
    "    img = img.astype(float) / 255.0\n",
    "    img = img.transpose(2, 0, 1) # NHWC -> NCHW\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img).float()\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    htan = nn.Hardtanh(0,1.0)\n",
    "    \n",
    "    # 모델로드\n",
    "    wc_model = get_model(wc_model_name, wc_n_classes, in_channels=3)\n",
    "    \n",
    "    if DEVICE.type == 'cpu':\n",
    "        wc_state = convert_state_dict(torch.load(wc_model_path, map_location='cpu')['model_state'])\n",
    "    else:\n",
    "        wc_state = convert_state_dict(torch.load(wc_model_path)['model_state'])\n",
    "        \n",
    "        \n",
    "    wc_model.load_state_dict(wc_state)\n",
    "    wc_model.eval()\n",
    "    bm_model = get_model(bm_model_name, bm_n_classes, in_channels=3)\n",
    "    if DEVICE.type == 'cpu':\n",
    "        bm_state = convert_state_dict(torch.load(bm_model_path, map_location='cpu')['model_state'])\n",
    "    else:\n",
    "        bm_state = convert_state_dict(torch.load(bm_model_path)['model_state'])\n",
    "    bm_model.load_state_dict(bm_state)\n",
    "    bm_model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        wc_model.cuda()\n",
    "        bm_model.cuda()\n",
    "        images = Variable(img.cuda())\n",
    "    else:\n",
    "        images = Variable(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        wc_outputs = wc_model(images)\n",
    "        pred_wc = htan(wc_outputs)\n",
    "        bm_input=F.interpolate(pred_wc, bm_img_size)\n",
    "        outputs_bm = bm_model(bm_input)\n",
    "\n",
    "    # call unwarp\n",
    "    uwpred=unwarp(imgorg, outputs_bm)\n",
    "    \n",
    "    return uwpred[:,:,::-1]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob('dataset/*.*')\n",
    "for img_path in images:\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # prediction\n",
    "    result = predict_image(img_path, wc_model_path, bm_model_path)\n",
    "    result = np.array(result,dtype=np.uint8)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize =(16,16))\n",
    "\n",
    "    ax1.imshow(img)\n",
    "    ax2.imshow(result)\n",
    "    fig.show()\n",
    "    fig.savefig('./result/'+img_path.split('/')[-1][:-3]+'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_tutorials"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "haiqv/anaconda3-tensorflow-2.2.0-notebook-gpu:1.0.0",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
